{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業目標: 使用CKiptagger進行各項的斷詞操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import 所需 libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#導入所需libraries\n",
    "#請import 1.可用於下載權重的library 2.建構自定義字典的library 3.斷詞, 詞性標注,與命名實體辨識libries\n",
    "from ckiptagger import data_utils, construct_dictionary, WS, POS, NER\n",
    "\n",
    "#請對下列文本字串進行斷詞, 詞性標注, 命名實體識別\n",
    "\n",
    "sentence_list = [\n",
    "    \"傅達仁今將執行安樂死，卻突然爆出自己20年前遭緯來體育台封殺，他不懂自己哪裡得罪到電視台。\",\n",
    "    \"美國參議院針對今天總統布什所提名的勞工部長趙小蘭展開認可聽證會，預料她將會很順利通過參議院支持，成為該國有史以來第一位的華裔女性內閣成員。\",\n",
    "    \"\",\n",
    "    \"土地公有政策?？還是土地婆有政策。.\",\n",
    "    \"… 你確定嗎… 不要再騙了……\",\n",
    "    \"最多容納59,000個人,或5.9萬人,再多就不行了.這是環評的結論.\",\n",
    "    \"科長說:1,坪數對人數為1:3。2,可以再增加。\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 進行斷詞, 詞性標注, 與命名實體識別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/embedding_character/token_list.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d54101979783>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#創建實例\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPOS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/ckiptagger/api.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_dir, disable_cuda)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_token_to_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_embedding_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"embedding_character\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdisable_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/ckiptagger/api.py\u001b[0m in \u001b[0;36m_load_embedding\u001b[0;34m(embedding_dir)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_load_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0mtoken_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"token_list.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     \u001b[0mtoken_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0mvector_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"vector_list.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/embedding_character/token_list.npy'"
     ]
    }
   ],
   "source": [
    "#創建實例\n",
    "ws = WS('../data/')\n",
    "pos = POS('../data/')\n",
    "ner = NER('../data/')\n",
    "\n",
    "#斷詞\n",
    "word_s = ws(sentence_list,\n",
    "            sentence_segmentation=True,\n",
    "            segment_delimiter_set={'?', '？', '!', '！', '。', ',','，', ';', ':', '、'})\n",
    "\n",
    "print(f'斷詞輸出: {word_s}')\n",
    "print('\\n')\n",
    "\n",
    "#詞性標注\n",
    "word_p = pos(word_s)\n",
    "\n",
    "print(f'詞性標注輸出: {word_p}')\n",
    "print('\\n')\n",
    "\n",
    "#命名實體識別\n",
    "word_n = ner(word_s, word_p)\n",
    "print(f'命名實體識別輸出: {word_n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#合併顯示輸出結果\n",
    "def combine_wandp(word_s, word_p):\n",
    "    assert len(word_s) == len(word_p)\n",
    "    \n",
    "    for w, p in zip(word_s, word_p):\n",
    "        print (f'{w}({p})', end='\\u3000')\n",
    "        \n",
    "for i, sentence in enumerate(sentence_list):\n",
    "    print(f'Input sentence: \\n {sentence}')\n",
    "    print('\\n')\n",
    "    \n",
    "    print(f'Segmentation with PoS: \\n')\n",
    "    combine_wandp(word_s[i], word_p[i])\n",
    "    \n",
    "    print ('\\n')\n",
    "    print('Named Entity Recognition:')\n",
    "    for n in sorted(word_n[i]):\n",
    "        print (n)\n",
    "    print ('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 帶入自定義字典\n",
    "\n",
    "觀察上面的輸出發現，斷詞結果將`年前`斷為`年`、`前`, 請使用自定義字典使斷詞結果依然維持為`年前`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定義字典\n",
    "word_to_weight = {\n",
    "    \"年前\": 1,\n",
    "}\n",
    "dictionary = construct_dictionary(word_to_weight)\n",
    "\n",
    "#帶入自定義字典進行斷詞\n",
    "ws = WS(\"../data\") #建構斷詞\n",
    "\n",
    "input_traditional_str = [\"傅達仁今將執行安樂死，卻突然爆出自己20年前遭緯來體育台封殺，他不懂自己哪裡得罪到電視台。\"]\n",
    "\n",
    "word_sentence_list = ws(\n",
    "    input_traditional_str,\n",
    "    sentence_segmentation = True, # To consider delimiters\n",
    "    segment_delimiter_set = {\",\", \"。\", \":\", \"?\", \"!\", \";\"}, # This is the defualt set of delimiters\n",
    "    recommend_dictionary = dictionary)\n",
    "\n",
    "\n",
    "print(word_sentence_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
